{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('X_train.csv')\n",
    "train, test = train_test_split(data,random_state = 1,test_size = 0.2)\n",
    "y_test = test['reting']\n",
    "y = train['reting']\n",
    "index = train.shape[0]\n",
    "test['reting'] = -1\n",
    "#разделили на трейн и тест, теперь опять ссоединим вместе, чтобы сразу чистить и генерить фичи на всем датасете\n",
    "df = train.append(test,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#можно как-то использовать колонку property, но так как это отборочный этап, и что-то сложное делать не будем, просто удалим колонку\n",
    "del df['property']\n",
    "# userName зашифрован в MD5, можно конечно попробовать расшифровать процентов 40% ников, по никам нагенерить признаки, вроди пола\n",
    "#и тд но мы это тоже делать не будем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#нагенерим фичи, связанные с датой\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['day'] = df['date'].apply(lambda x: x.day)\n",
    "df['weekday'] = df['date'].apply(lambda x: x.weekday())\n",
    "df['month'] = df['date'].apply(lambda x: x.month)\n",
    "df['year'] = df['date'].apply(lambda x: x.year)\n",
    "del df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['commentNegative'] = df['commentNegative'].fillna('')\n",
    "df['commentPositive'] = df['commentPositive'].fillna('')\n",
    "df['commentPositive_len'] = df['commentPositive'].str.len()\n",
    "df['commentNegative_len'] = df['commentNegative'].str.len()\n",
    "df['comment_len'] = df['comment'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#так как commentNegative и commentNegative во многих отзывах пропущены, то просто склеим их к коменту и удалим\n",
    "#в роли флага, был ли негативный или позитинвый коммент, будет выступать commentNegative_len и commentPositive_len\n",
    "df['comment'] = df['comment'] + ' œ ' + df['commentPositive'] + ' å ' +  df['commentNegative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['comment_len_all'] = df['comment'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['commentNegative']\n",
    "del df['commentPositive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average(col,alpha = 10,y_target = 'reting'):\n",
    "    ans = pd.Series(index = df.index)#создали пустой массив, с индексами,и размерностью df\n",
    "    X_train = df[df['reting'] != -1][[col,y_target]]#создали новый датафрейм из друх колонок:колонки col and y_target, берем только трейн данные\n",
    "    X_test = df[df['reting'] == -1][col]#копируем колонку col тест данных\n",
    "    mean_by_col = X_train.groupby(col).mean()[y_target]#для каждого уникального значения колонки col найдем средний таргет\n",
    "    counts = X_train[col].value_counts()#подсчитаем количество каждого уникального значения col\n",
    "    mean = X_train[y_target].mean()# запомним глобальное среднее таргета\n",
    "    ans_test = X_test.apply(lambda x: (mean_by_col[x]*counts[x] + alpha*mean) / (counts[x] + alpha)  if x in counts.index else mean)\n",
    "    #строчка выше вычисляет формулу из видео\n",
    "    ans[ans_test.index] = ans_test#на нужные инлексы запишем наш полученный результат.\n",
    "    #это мы зная весь трейн, вычислили сркднее по таргету для теста. Теперь надо получить также среднее для трейна, но чтобы не переобучаться\n",
    "    #мы должны использовать кросс валидацию.Перемешаем и Разобьем трецн на 5 частей. на 4 частях будем обучатьсч, а на пятой предсказывать\n",
    "    kf = KFold(n_splits=5,random_state=42,shuffle = True)\n",
    "    for train_i,test_i in kf.split(X_train):\n",
    "        #train_i - индексы, которые попали в первые 4 части и на них будем обучаться\n",
    "        #test_i -индексы для которых будем делать предсказания\n",
    "        #теперь делаем все тоже самое, что и выше, когда мы предсказывали среднее для теста по трейну\n",
    "        X = X_train.iloc[train_i]\n",
    "        X_t = X_train.iloc[test_i,0]\n",
    "        mean_by_col = X.groupby(col).mean()[y_target]\n",
    "        counts = X[col].value_counts()\n",
    "        mean = X[y_target].mean()\n",
    "        ans_test = X_t.apply(lambda x: (mean_by_col[x]*counts[x] + alpha*mean) / (counts[x] + alpha)  if x in counts.index else mean)\n",
    "        ans[ans_test.index] = ans_test\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#как учил Семенов, делаем mean target для всех колонок. Двойную кросс валидацию делать не будем, так как и так сойдет =) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_to_mean_target = ['sku','categoryLevel1Id','categoryLevel2Id','brandId','userName','day','weekday','month',\n",
    "                     'year','commentPositive_len','commentNegative_len','comment_len','comment_len_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in col_to_mean_target:\n",
    "    df[i + '_mean_target'] = average(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь еще одна сложная штука для понимания, но простая в реализации. Это субъективное восприятие товара человеком. Бывают люди гурманы, которые считают что все товары говно, и всегда ставят оценку к товару ниже, чем средняя оценка. А есть наоборот, люди, которым все товары нравятся и они ставят завышенную оценку. Создадим новую переменную: разницу между оценкой, которую поставил человек и средней оценкой товара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tmp'] = df['reting'] - df['categoryLevel2Id_mean_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь применим среднее по таргету для кажого человека, при этом таргетом у нас как раз будет tmp переменная. Что мы получили? Получили на сколько в среднем отзыв человека ниже/выше среднего отзыва о товаре. Ну и добавим новую фичу: предпологаемая оценка товара человеком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['delta_score'] = average('userName',alpha=1,y_target='tmp')\n",
    "df['predict'] = df['categoryLevel2Id_mean_target'] + df['delta_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Теперь займемся самими текстами. Не будем использовать модные word2vec, нейронки, LSTM, а возьмем добрый, проверенный временем мешок слов tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как организарты не обозначили конкретную метрику, то будем использовать MSE, так как у нас отзывы упорядочены. В конце будем просто округлять до целого."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с помощью GridSearchCV найдем оптимальные параметры для TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [mean: -1.07582, std: 0.02202, params: {'alpha': 0.1}]\n",
      "2 [mean: -0.93290, std: 0.02947, params: {'alpha': 0.1}]\n",
      "3 [mean: -1.00315, std: 0.03014, params: {'alpha': 0.1}]\n",
      "CPU times: user 29.6 s, sys: 2.01 s, total: 31.7 s\n",
      "Wall time: 37.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1,4):\n",
    "    tf = TfidfVectorizer(ngram_range=(1,i))\n",
    "    summary = tf.fit_transform(df['comment'])\n",
    "    grid ={'alpha':[0.1]}\n",
    "    gr = GridSearchCV(Ridge(),grid,cv = 2,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "    gr.fit(summary[:index],y)\n",
    "    print i,gr.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 [mean: -0.89924, std: 0.02366, params: {'alpha': 0.1}]\n",
      "200000 [mean: -0.90170, std: 0.02656, params: {'alpha': 0.1}]\n",
      "300000 [mean: -0.91243, std: 0.02804, params: {'alpha': 0.1}]\n",
      "400000 [mean: -0.92382, std: 0.02876, params: {'alpha': 0.1}]\n",
      "500000 [mean: -0.93288, std: 0.02944, params: {'alpha': 0.1}]\n",
      "600000 [mean: -0.93290, std: 0.02946, params: {'alpha': 0.1}]\n",
      "700000 [mean: -0.93286, std: 0.02945, params: {'alpha': 0.1}]\n",
      "800000 [mean: -0.93286, std: 0.02947, params: {'alpha': 0.1}]\n",
      "900000 [mean: -0.93289, std: 0.02945, params: {'alpha': 0.1}]\n",
      "1000000 [mean: -0.93288, std: 0.02946, params: {'alpha': 0.1}]\n",
      "CPU times: user 1min 31s, sys: 4.95 s, total: 1min 36s\n",
      "Wall time: 1min 53s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100000,1100000,100000):\n",
    "    tf = TfidfVectorizer(ngram_range=(1,2),max_features =  int(i))\n",
    "    summary = tf.fit_transform(df['comment'])\n",
    "    grid ={'alpha':[0.1]}\n",
    "    gr = GridSearchCV(Ridge(),grid,cv = 2,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "    gr.fit(summary[:index],y)\n",
    "    print i,gr.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 [mean: -1.19361, std: 0.02797, params: {'alpha': 0.1}]\n",
      "20000 [mean: -1.01777, std: 0.02566, params: {'alpha': 0.1}]\n",
      "30000 [mean: -0.96122, std: 0.02379, params: {'alpha': 0.1}]\n",
      "40000 [mean: -0.93686, std: 0.02254, params: {'alpha': 0.1}]\n",
      "50000 [mean: -0.91983, std: 0.02415, params: {'alpha': 0.1}]\n",
      "60000 [mean: -0.91200, std: 0.02460, params: {'alpha': 0.1}]\n",
      "70000 [mean: -0.90527, std: 0.02445, params: {'alpha': 0.1}]\n",
      "80000 [mean: -0.90033, std: 0.02364, params: {'alpha': 0.1}]\n",
      "90000 [mean: -0.90027, std: 0.02389, params: {'alpha': 0.1}]\n",
      "100000 [mean: -0.89925, std: 0.02365, params: {'alpha': 0.1}]\n",
      "CPU times: user 1min 17s, sys: 4.07 s, total: 1min 21s\n",
      "Wall time: 1min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(10000,110000,10000):\n",
    "    tf = TfidfVectorizer(ngram_range=(1,2),max_features =  int(i))\n",
    "    summary = tf.fit_transform(df['comment'])\n",
    "    grid ={'alpha':[0.1]}\n",
    "    gr = GridSearchCV(Ridge(),grid,cv = 2,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "    gr.fit(summary[:index],y)\n",
    "    print i,gr.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нашли оптимальные параметры для  tfidf: ngram_range=(1,2),max_features = 100000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы создали новые фичи. Возьмем фичи, которые увеличивают score. И отнормируем их, так как мы будем использовать линейную регрессию с l2 регуляризацией, ее также называют Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df[['delta_score','predict','comment_len_all_mean_target','comment_len_mean_target',\n",
    "    'commentNegative_len_mean_target','commentPositive_len_mean_target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "data_s=ss.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = hstack([summary[index:,],data_s[index:,]])\n",
    "X_train = hstack([summary[:index,],data_s[:index,]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки результатов, отбора фич и настройки параметра alpha, я использовал кросс-валидацию. Для этого использовал GridSearchCV. Так как данные хорошо были перемешаны, то достаточно было использовать всего два фолда, т е разбивать трейн на две части, на одной обучать, а на другой проверять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 640 ms, total: 11.1 s\n",
      "Wall time: 2min 18s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid ={'alpha':np.linspace(0.000000000001,0.1,15)}\n",
    "gr = GridSearchCV(Ridge(),grid,cv = 2,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "gr.fit(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -0.89177, std: 0.02741, params: {'alpha': 9.9999999999999998e-13},\n",
       " mean: -0.89212, std: 0.02734, params: {'alpha': 0.007142857143785715},\n",
       " mean: -0.89240, std: 0.02750, params: {'alpha': 0.014285714286571429},\n",
       " mean: -0.89274, std: 0.02742, params: {'alpha': 0.021428571429357141},\n",
       " mean: -0.89309, std: 0.02736, params: {'alpha': 0.028571428572142857},\n",
       " mean: -0.89355, std: 0.02740, params: {'alpha': 0.035714285714928573},\n",
       " mean: -0.89395, std: 0.02725, params: {'alpha': 0.042857142857714282},\n",
       " mean: -0.89433, std: 0.02737, params: {'alpha': 0.050000000000499999},\n",
       " mean: -0.89466, std: 0.02746, params: {'alpha': 0.057142857143285715},\n",
       " mean: -0.89501, std: 0.02738, params: {'alpha': 0.064285714286071438},\n",
       " mean: -0.89556, std: 0.02741, params: {'alpha': 0.071428571428857154},\n",
       " mean: -0.89604, std: 0.02745, params: {'alpha': 0.078571428571642871},\n",
       " mean: -0.89630, std: 0.02747, params: {'alpha': 0.085714285714428573},\n",
       " mean: -0.89666, std: 0.02738, params: {'alpha': 0.092857142857214289},\n",
       " mean: -0.89708, std: 0.02742, params: {'alpha': 0.10000000000000001}]"
      ]
     },
     "execution_count": 216,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут можно много что еще делать, юзать xgb, нейронку, потом запилить стекинг, но так как это тестовое задание, и в github вбив в поиск mvideo, можно посмотреть решения других участников, то понятно, что участников не так много, так что можно остановиться на этом. Теперь просто предскажем нашей моделью тестовые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1e-12, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 217,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg = Ridge(alpha=9.9999999999999998e-13)\n",
    "rg.fit(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = rg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.85679125311542081"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#MSE\n",
    "metrics.mean_squared_error(y_test,ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 3.38185203,  4.84287723,  5.11438313, ...,  3.17035521,\n",
       "        3.38514497,  3.77308691])"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
