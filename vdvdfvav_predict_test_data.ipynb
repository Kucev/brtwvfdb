{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Орги попросили прогнать код на их тестовых даных и предсказать их. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.sparse import hstack\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#train, test = train_test_split(data,random_state = 1,test_size = 0.2)\n",
    "train = pd.read_csv('X_train.csv')\n",
    "test = pd.read_csv('X_final_test.csv')\n",
    "uuid = test['uuid']\n",
    "del test['uuid']\n",
    "#y_test = test['reting']\n",
    "y = train['reting']\n",
    "index = train.shape[0]\n",
    "test['reting'] = -1\n",
    "#разделили на трейн и тест, теперь опять ссоединим вместе, чтобы сразу чистить и генерить фичи на всем датасете\n",
    "df = train.append(test,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#можно как-то использовать колонку property, но так как это отборочный этап, и что-то сложное делать не будем, просто удалим колонку\n",
    "del df['property']\n",
    "# userName зашифрован в MD5, можно конечно попробовать расшифровать процентов 40% ников, по никам нагенерить признаки, вроди пола\n",
    "#и тд но мы это тоже делать не будем"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#нагенерим фичи, связанные с датой\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df['day'] = df['date'].apply(lambda x: x.day)\n",
    "df['weekday'] = df['date'].apply(lambda x: x.weekday())\n",
    "df['month'] = df['date'].apply(lambda x: x.month)\n",
    "df['year'] = df['date'].apply(lambda x: x.year)\n",
    "del df['date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['commentNegative'] = df['commentNegative'].fillna('')\n",
    "df['commentPositive'] = df['commentPositive'].fillna('')\n",
    "df['commentPositive_len'] = df['commentPositive'].str.len()\n",
    "df['commentNegative_len'] = df['commentNegative'].str.len()\n",
    "df['comment_len'] = df['comment'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#так как commentNegative и commentNegative во многих отзывах пропущены, то просто склеим их к коменту и удалим\n",
    "#в роли флага, был ли негативный или позитинвый коммент, будет выступать commentNegative_len и commentPositive_len\n",
    "df['comment'] = df['comment'] + ' œ ' + df['commentPositive'] + ' å ' +  df['commentNegative']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['comment_len_all'] = df['comment'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "del df['commentNegative']\n",
    "del df['commentPositive']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average(col,alpha = 10,y_target = 'reting'):\n",
    "    ans = pd.Series(index = df.index)#создали пустой массив, с индексами,и размерностью df\n",
    "    X_train = df[df['reting'] != -1][[col,y_target]]#создали новый датафрейм из друх колонок:колонки col and y_target, берем только трейн данные\n",
    "    X_test = df[df['reting'] == -1][col]#копируем колонку col тест данных\n",
    "    mean_by_col = X_train.groupby(col).mean()[y_target]#для каждого уникального значения колонки col найдем средний таргет\n",
    "    counts = X_train[col].value_counts()#подсчитаем количество каждого уникального значения col\n",
    "    mean = X_train[y_target].mean()# запомним глобальное среднее таргета\n",
    "    ans_test = X_test.apply(lambda x: (mean_by_col[x]*counts[x] + alpha*mean) / (counts[x] + alpha)  if x in counts.index else mean)\n",
    "    #строчка выше вычисляет формулу из видео\n",
    "    ans[ans_test.index] = ans_test#на нужные инлексы запишем наш полученный результат.\n",
    "    #это мы зная весь трейн, вычислили сркднее по таргету для теста. Теперь надо получить также среднее для трейна, но чтобы не переобучаться\n",
    "    #мы должны использовать кросс валидацию.Перемешаем и Разобьем трецн на 5 частей. на 4 частях будем обучатьсч, а на пятой предсказывать\n",
    "    kf = KFold(n_splits=5,random_state=42,shuffle = True)\n",
    "    for train_i,test_i in kf.split(X_train):\n",
    "        #train_i - индексы, которые попали в первые 4 части и на них будем обучаться\n",
    "        #test_i -индексы для которых будем делать предсказания\n",
    "        #теперь делаем все тоже самое, что и выше, когда мы предсказывали среднее для теста по трейну\n",
    "        X = X_train.iloc[train_i]\n",
    "        X_t = X_train.iloc[test_i,0]\n",
    "        mean_by_col = X.groupby(col).mean()[y_target]\n",
    "        counts = X[col].value_counts()\n",
    "        mean = X[y_target].mean()\n",
    "        ans_test = X_t.apply(lambda x: (mean_by_col[x]*counts[x] + alpha*mean) / (counts[x] + alpha)  if x in counts.index else mean)\n",
    "        ans[ans_test.index] = ans_test\n",
    "    return ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#как учил Семенов, делаем mean target для всех колонок. Двойную кросс валидацию делать не будем, так как и так сойдет =) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "col_to_mean_target = ['sku','categoryLevel1Id','categoryLevel2Id','brandId','userName','day','weekday','month',\n",
    "                     'year','commentPositive_len','commentNegative_len','comment_len','comment_len_all']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for i in col_to_mean_target:\n",
    "    df[i + '_mean_target'] = average(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь еще одна сложная штука для понимания, но простая в реализации. Это субъективное восприятие товара человеком. Бывают люди гурманы, которые считают что все товары говно, и всегда ставят оценку к товару ниже, чем средняя оценка. А есть наоборот, люди, которым все товары нравятся и они ставят завышенную оценку. Создадим новую переменную: разницу между оценкой, которую поставил человек и средней оценкой товара"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['tmp'] = df['reting'] - df['categoryLevel2Id_mean_target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "И теперь применим среднее по таргету для кажого человека, при этом таргетом у нас как раз будет tmp переменная. Что мы получили? Получили на сколько в среднем отзыв человека ниже/выше среднего отзыва о товаре. Ну и добавим новую фичу: предпологаемая оценка товара человеком."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df['delta_score'] = average('userName',alpha=1,y_target='tmp')\n",
    "df['predict'] = df['categoryLevel2Id_mean_target'] + df['delta_score']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Теперь займемся самими текстами. Не будем использовать модные word2vec, нейронки, LSTM, а возьмем добрый, проверенный временем мешок слов tfidf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Так как организарты не обозначили конкретную метрику, то будем использовать MSE, так как у нас отзывы упорядочены. В конце будем просто округлять до целого."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "с помощью GridSearchCV найдем оптимальные параметры для TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 [mean: -1.07009, std: 0.00022, params: {'alpha': 0.1}]\n",
      "2 [mean: -0.90761, std: 0.01000, params: {'alpha': 0.1}]\n",
      "3 [mean: -0.97064, std: 0.01215, params: {'alpha': 0.1}]\n",
      "CPU times: user 31.1 s, sys: 1.45 s, total: 32.5 s\n",
      "Wall time: 38.1 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(1,4):\n",
    "    tf = TfidfVectorizer(ngram_range=(1,i))\n",
    "    summary = tf.fit_transform(df['comment'])\n",
    "    grid ={'alpha':[0.1]}\n",
    "    gr = GridSearchCV(Ridge(),grid,cv = 2,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "    gr.fit(summary[:index],y)\n",
    "    print i,gr.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 [mean: -0.89040, std: 0.00150, params: {'alpha': 0.1}]\n",
      "200000 [mean: -0.88271, std: 0.00148, params: {'alpha': 0.1}]\n",
      "300000 [mean: -0.88949, std: 0.00558, params: {'alpha': 0.1}]\n",
      "400000 [mean: -0.89930, std: 0.00838, params: {'alpha': 0.1}]\n",
      "500000 [mean: -0.90762, std: 0.01000, params: {'alpha': 0.1}]\n",
      "600000 [mean: -0.90762, std: 0.01001, params: {'alpha': 0.1}]\n",
      "700000 [mean: -0.90762, std: 0.01000, params: {'alpha': 0.1}]\n",
      "800000 [mean: -0.90761, std: 0.00999, params: {'alpha': 0.1}]\n",
      "900000 [mean: -0.90761, std: 0.00999, params: {'alpha': 0.1}]\n",
      "1000000 [mean: -0.90762, std: 0.01001, params: {'alpha': 0.1}]\n",
      "CPU times: user 1min 37s, sys: 5.17 s, total: 1min 42s\n",
      "Wall time: 2min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100000,1100000,100000):\n",
    "    tf = TfidfVectorizer(ngram_range=(1,2),max_features =  int(i))\n",
    "    summary = tf.fit_transform(df['comment'])\n",
    "    grid ={'alpha':[0.1]}\n",
    "    gr = GridSearchCV(Ridge(),grid,cv = 2,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "    gr.fit(summary[:index],y)\n",
    "    print i,gr.grid_scores_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 [mean: -0.89041, std: 0.00152, params: {'alpha': 0.1}]\n",
      "110000 [mean: -0.88852, std: 0.00226, params: {'alpha': 0.1}]\n",
      "120000 [mean: -0.88726, std: 0.00251, params: {'alpha': 0.1}]\n",
      "130000 [mean: -0.88561, std: 0.00177, params: {'alpha': 0.1}]\n",
      "140000 [mean: -0.88450, std: 0.00103, params: {'alpha': 0.1}]\n",
      "150000 [mean: -0.88318, std: 0.00034, params: {'alpha': 0.1}]\n",
      "160000 [mean: -0.88233, std: 0.00000, params: {'alpha': 0.1}]\n",
      "170000 [mean: -0.88252, std: 0.00041, params: {'alpha': 0.1}]\n",
      "180000 [mean: -0.88264, std: 0.00068, params: {'alpha': 0.1}]\n",
      "190000 [mean: -0.88224, std: 0.00134, params: {'alpha': 0.1}]\n",
      "200000 [mean: -0.88275, std: 0.00148, params: {'alpha': 0.1}]\n",
      "210000 [mean: -0.88292, std: 0.00192, params: {'alpha': 0.1}]\n",
      "220000 [mean: -0.88306, std: 0.00234, params: {'alpha': 0.1}]\n",
      "230000 [mean: -0.88369, std: 0.00270, params: {'alpha': 0.1}]\n",
      "240000 [mean: -0.88461, std: 0.00350, params: {'alpha': 0.1}]\n",
      "250000 [mean: -0.88524, std: 0.00366, params: {'alpha': 0.1}]\n",
      "260000 [mean: -0.88554, std: 0.00379, params: {'alpha': 0.1}]\n",
      "270000 [mean: -0.88644, std: 0.00454, params: {'alpha': 0.1}]\n",
      "280000 [mean: -0.88751, std: 0.00490, params: {'alpha': 0.1}]\n",
      "290000 [mean: -0.88831, std: 0.00530, params: {'alpha': 0.1}]\n",
      "CPU times: user 2min 58s, sys: 9.15 s, total: 3min 7s\n",
      "Wall time: 3min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100000,300000,10000):\n",
    "    tf = TfidfVectorizer(ngram_range=(1,2),max_features =  int(i))\n",
    "    summary = tf.fit_transform(df['comment'])\n",
    "    grid ={'alpha':[0.1]}\n",
    "    gr = GridSearchCV(Ridge(),grid,cv = 2,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "    gr.fit(summary[:index],y)\n",
    "    print i,gr.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нашли оптимальные параметры для  tfidf: ngram_range=(1,2),max_features = 160000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы создали новые фичи. Возьмем фичи, которые увеличивают score. И отнормируем их, так как мы будем использовать линейную регрессию с l2 регуляризацией, ее также называют Ridge."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = df[['delta_score','predict','comment_len_all_mean_target','comment_len_mean_target',\n",
    "    'commentNegative_len_mean_target','commentPositive_len_mean_target']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ss = StandardScaler()\n",
    "data_s=ss.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(ngram_range=(1,2),max_features = 160000)\n",
    "summary = tf.fit_transform(df['comment'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_test = hstack([summary[index:,],data_s[index:,]])\n",
    "X_train = hstack([summary[:index,],data_s[:index,]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Для проверки результатов, отбора фич и настройки параметра alpha, я использовал кросс-валидацию. Для этого использовал GridSearchCV. Так как данные хорошо были перемешаны, то достаточно было использовать всего два фолда, т е разбивать трейн на две части, на одной обучать, а на другой проверять."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 12.3 s, sys: 352 ms, total: 12.6 s\n",
      "Wall time: 2min 11s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "grid ={'alpha':np.linspace(0.000000000001,0.1,15)}\n",
    "gr = GridSearchCV(Ridge(),grid,cv = 2,scoring='neg_mean_squared_error',n_jobs=-1)\n",
    "gr.fit(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[mean: -0.87825, std: 0.00780, params: {'alpha': 9.9999999999999998e-13},\n",
       " mean: -0.87872, std: 0.00782, params: {'alpha': 0.007142857143785715},\n",
       " mean: -0.87896, std: 0.00764, params: {'alpha': 0.014285714286571429},\n",
       " mean: -0.87943, std: 0.00766, params: {'alpha': 0.021428571429357141},\n",
       " mean: -0.87988, std: 0.00791, params: {'alpha': 0.028571428572142857},\n",
       " mean: -0.88025, std: 0.00781, params: {'alpha': 0.035714285714928573},\n",
       " mean: -0.88062, std: 0.00769, params: {'alpha': 0.042857142857714282},\n",
       " mean: -0.88110, std: 0.00771, params: {'alpha': 0.050000000000499999},\n",
       " mean: -0.88160, std: 0.00779, params: {'alpha': 0.057142857143285715},\n",
       " mean: -0.88197, std: 0.00770, params: {'alpha': 0.064285714286071438},\n",
       " mean: -0.88224, std: 0.00789, params: {'alpha': 0.071428571428857154},\n",
       " mean: -0.88262, std: 0.00800, params: {'alpha': 0.078571428571642871},\n",
       " mean: -0.88310, std: 0.00782, params: {'alpha': 0.085714285714428573},\n",
       " mean: -0.88348, std: 0.00772, params: {'alpha': 0.092857142857214289},\n",
       " mean: -0.88386, std: 0.00782, params: {'alpha': 0.10000000000000001}]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gr.grid_scores_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Тут можно много что еще делать, юзать xgb, нейронку, потом запилить стекинг, но так как это тестовое задание, и в github вбив в поиск mvideo, можно посмотреть решения других участников, то понятно, что участников не так много, так что можно остановиться на этом. Теперь просто предскажем нашей моделью тестовые данные."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1e-12, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rg = Ridge(alpha=9.9999999999999998e-13)\n",
    "rg.fit(X_train,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ans = rg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test['reting'] = ans\n",
    "test['uuid'] = uuid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test.to_csv('ans.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sku</th>\n",
       "      <th>categoryLevel1Id</th>\n",
       "      <th>categoryLevel2Id</th>\n",
       "      <th>brandId</th>\n",
       "      <th>property</th>\n",
       "      <th>userName</th>\n",
       "      <th>date</th>\n",
       "      <th>comment</th>\n",
       "      <th>commentNegative</th>\n",
       "      <th>commentPositive</th>\n",
       "      <th>reting</th>\n",
       "      <th>uuid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20003635</td>\n",
       "      <td>406</td>\n",
       "      <td>4060501</td>\n",
       "      <td>62</td>\n",
       "      <td>[{719: 'a9b7ba70783b617e9998dc4dd82eb3c5'}, {1...</td>\n",
       "      <td>e033ded0ac328c61d6b007139ec4e219</td>\n",
       "      <td>2012-04-16</td>\n",
       "      <td>Согласна с Сашей и Наташей. Самая лучшая,самая...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.901586</td>\n",
       "      <td>e0880553-b7f1-4eaa-a800-966133bda683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20000782</td>\n",
       "      <td>411</td>\n",
       "      <td>4110104</td>\n",
       "      <td>13</td>\n",
       "      <td>[{34: '9ce895413ebdf6b6dcb69b07dc782591'}, {36...</td>\n",
       "      <td>9f269ce1c8e74e7b1e63f55b856068cd</td>\n",
       "      <td>2010-12-11</td>\n",
       "      <td>Хороший пылесос. Вроде качественный. Да, шумно...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.753868</td>\n",
       "      <td>30039f3f-e719-4b47-b588-9a05fd11a799</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20021828</td>\n",
       "      <td>413</td>\n",
       "      <td>4130401</td>\n",
       "      <td>63</td>\n",
       "      <td>[{34: 'f982777489055c6563d68c005fd24aad'}, {36...</td>\n",
       "      <td>dc9731cd5ea3ab7e16401cc678d046a5</td>\n",
       "      <td>2012-11-02</td>\n",
       "      <td>Пользовалась им почти 2 года, без нареканий. Н...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.651724</td>\n",
       "      <td>352a5abc-10f4-4668-ae5a-a4285413811a</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20027435</td>\n",
       "      <td>413</td>\n",
       "      <td>4130301</td>\n",
       "      <td>678</td>\n",
       "      <td>[{539: '47c7a779688d5f67c55a42811da13210'}, {3...</td>\n",
       "      <td>c9b5ecdf0b853aab02103542187ea208</td>\n",
       "      <td>2016-04-22</td>\n",
       "      <td>До этого у меня был триммер всего с одной наса...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.650282</td>\n",
       "      <td>bfe4564d-944c-4680-b1ce-14e5486ada52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20004128</td>\n",
       "      <td>413</td>\n",
       "      <td>4130401</td>\n",
       "      <td>1466</td>\n",
       "      <td>[{162: 'f932bed2d12442d21507b51d22b88dd7'}, {2...</td>\n",
       "      <td>32bf3da6fec001612d3e5048d87c5c64</td>\n",
       "      <td>2009-10-22</td>\n",
       "      <td>Удобны в использовании. Волосы становятся глад...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.905330</td>\n",
       "      <td>13547ee0-3400-422f-b831-528caeda9c69</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        sku  categoryLevel1Id  categoryLevel2Id  brandId  \\\n",
       "0  20003635               406           4060501       62   \n",
       "1  20000782               411           4110104       13   \n",
       "2  20021828               413           4130401       63   \n",
       "3  20027435               413           4130301      678   \n",
       "4  20004128               413           4130401     1466   \n",
       "\n",
       "                                            property  \\\n",
       "0  [{719: 'a9b7ba70783b617e9998dc4dd82eb3c5'}, {1...   \n",
       "1  [{34: '9ce895413ebdf6b6dcb69b07dc782591'}, {36...   \n",
       "2  [{34: 'f982777489055c6563d68c005fd24aad'}, {36...   \n",
       "3  [{539: '47c7a779688d5f67c55a42811da13210'}, {3...   \n",
       "4  [{162: 'f932bed2d12442d21507b51d22b88dd7'}, {2...   \n",
       "\n",
       "                           userName        date  \\\n",
       "0  e033ded0ac328c61d6b007139ec4e219  2012-04-16   \n",
       "1  9f269ce1c8e74e7b1e63f55b856068cd  2010-12-11   \n",
       "2  dc9731cd5ea3ab7e16401cc678d046a5  2012-11-02   \n",
       "3  c9b5ecdf0b853aab02103542187ea208  2016-04-22   \n",
       "4  32bf3da6fec001612d3e5048d87c5c64  2009-10-22   \n",
       "\n",
       "                                             comment commentNegative  \\\n",
       "0  Согласна с Сашей и Наташей. Самая лучшая,самая...             NaN   \n",
       "1  Хороший пылесос. Вроде качественный. Да, шумно...             NaN   \n",
       "2  Пользовалась им почти 2 года, без нареканий. Н...             NaN   \n",
       "3  До этого у меня был триммер всего с одной наса...             NaN   \n",
       "4  Удобны в использовании. Волосы становятся глад...             NaN   \n",
       "\n",
       "  commentPositive    reting                                  uuid  \n",
       "0             NaN  4.901586  e0880553-b7f1-4eaa-a800-966133bda683  \n",
       "1             NaN  4.753868  30039f3f-e719-4b47-b588-9a05fd11a799  \n",
       "2             NaN  3.651724  352a5abc-10f4-4668-ae5a-a4285413811a  \n",
       "3             NaN  4.650282  bfe4564d-944c-4680-b1ce-14e5486ada52  \n",
       "4             NaN  4.905330  13547ee0-3400-422f-b831-528caeda9c69  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
